{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get isolines from the Here API. \n",
    "\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoSeries\n",
    "from shapely.geometry import Polygon\n",
    "import folium\n",
    "import citydelconfig as config\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "name = \"hereapi\"\n",
    "ID = config.here_api_key\n",
    "code = config.here_api_code\n",
    "\n",
    "head = 'https://isoline.route.cit.api.here.com/routing/7.2/calculateisoline.json?'\n",
    "URL_Base = '{}app_id={}&app_code={}&mode=fastest;{};traffic:{}&start=geo!{},{}&range={}&rangetype={}'\n",
    "URL_Base_dep = '{}app_id={}&app_code={}&mode=fastest;{};traffic:{}&departure={}&start=geo!{},{}&range={}&rangetype={}'\n",
    "\n",
    "def get_isodata(location, type_iso = 'time', range_iso = 3600, travel_mode = 'car', traffic='disabled', departure=None): #receives a single location\n",
    "    \"\"\" Function uses Here API to generate isolines depending on input parameters\n",
    "    \n",
    "    Parameters:\n",
    "    location - Tuple of coordinates (lat, long)\n",
    "    type_iso - Type of isoline, distance or time based, defaults to time\n",
    "    range_iso - Range of the isoline depending on type_iso (in seconds), defaults to 1 hour\n",
    "    travel_mode - Type of transit, can be truck, car or pedestrian\n",
    "    traffic - toggles enabled or disabled\n",
    "    departure - Departure time in format YYYY-MM-DDTHH:MM:SS (can include timezone)\n",
    "    \"\"\"\n",
    "    \n",
    "    if departure == None:\n",
    "        url = URL_Base.format(head, ID, CODE, travel_mode, traffic, location[0], location[1], range_iso, type_iso) \n",
    "    else: \n",
    "        url = URL_Base_dep.format(head, ID, CODE, travel_mode, traffic, departure, location[0], location[1], range_iso, type_iso)\n",
    "    try: \n",
    "        js = requests.get(url).json()['response']\n",
    "        iso = js['isoline']\n",
    "        coords = Polygon([(float(x.split(',')[1]), float(x.split(',')[0])) for x in iso[0]['component'][0]['shape']])\n",
    "        geojs = gpd.GeoSeries([coords])\n",
    "        geojs.crs = {'init' : 'epsg:4326'}\n",
    "        return geojs\n",
    "    except KeyError:\n",
    "        js = requests.get(url).json()\n",
    "        print(js)\n",
    "        raise ValueError(\"HereAPI doesn't have data requested\")\n",
    "    except IndexError:\n",
    "        raise ValueError(\"HereAPI doesn't have quality data\")\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot isoline on a map, needs coordinates to start out\n",
    "\n",
    "def isoplot(center, locations, outputfile = 'out.html'):\n",
    "    \"\"\" Function creates a plot of the isoline on top of a map\n",
    "    \n",
    "    Parameters:\n",
    "    center - Center for the map to be created (lat, long)\n",
    "    locations - Geoseries/Geodataframe of isoline/isolines\n",
    "    outputfile - Output location in .html extension\n",
    "    \"\"\"\n",
    "    \n",
    "    fm = folium.Map(location = center, zoom_start=10, tiles='CartoDBPositron')\n",
    "    geojson = locations.__geo_interface__\n",
    "    geojson['style'] = {\"__comment\": \"all SVG styles allowed\", \"fill\":\"red\", \"stroke-width\":\"3\", \"fill-opacity\":0.6}\n",
    "    folium.GeoJson(geojson).add_to(fm)\n",
    "    fm.save(outputfile)\n",
    "    print('map saved to %s' %outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondary functions for different types of input data to plot\n",
    "    \n",
    "def isoplot_contour(center, locations, outputfile):\n",
    "    #takes a center, and a list of isolines to create a contour map\n",
    "    fm = folium.Map(location = center, zoom_start = 10, tiles = 'CartoDBPositron')\n",
    "    for loc in locations:\n",
    "        geojson = loc.__geo_interface__\n",
    "        geojson['style'] = {\"__comment\": \"all SVG styles allowed\", \"fill\":\"red\", \"stroke-width\":\"3\", \"fill-opacity\":0.6}\n",
    "        folium.GeoJson(geojson).add_to(fm)\n",
    "    fm.save(outputfile)\n",
    "    print('map saved to %s' %outputfile)\n",
    "    \n",
    "def get_isodata_list(locations, range_iso = 3600, type_iso = 'time', traffic = 'disabled'): \n",
    "    #recevies many locations, as a list of tuples of locations\n",
    "    isoclines = []\n",
    "    for loc in locations: \n",
    "        try:\n",
    "            line = get_isodata(loc, range_iso, type_iso, traffic)\n",
    "            isoclines.append(line)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return isoclines\n",
    "\n",
    "        \n",
    "def make_list(centers, names, color, range_iso = 3600, type_iso = 'time', traffic = 'disabled'):\n",
    "    for i, center in enumerate(centers):\n",
    "        try:\n",
    "            line = get_isodata(center, range_iso, type_iso, traffic)    \n",
    "        except ValueError:\n",
    "            pass\n",
    "        isoplot(center, line, 'red', 'isoclines/' + names[i] +'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map saved to abad.html\n",
      "map saved to ../abad_traffic.html\n",
      "map saved to mumbai_traffic.html\n",
      "map saved to mumbai_notraffic2.html\n",
      "map saved to ny_traffic.html\n"
     ]
    }
   ],
   "source": [
    "#examples of using get_isodata and isoplot for different cities and times\n",
    "\n",
    "abad_center = (23.027496, 72.572697)\n",
    "locsabad = get_isodata(abad_center, range_iso = 3600, type_iso = 'time')\n",
    "isoplot(abad_center, locsabad,'abad.html')\n",
    "locsabad2 = get_isodata(abad_center, traffic='enabled', departure='2019-02-13T17:00:00')\n",
    "isoplot(abad_center, locsabad2, '../abad_traffic.html')\n",
    "\n",
    "mumbai_center = (19.060828, 72.872478)\n",
    "locs = get_isodata(mumbai_center, traffic='enabled', departure='2019-02-13T17:00:00')\n",
    "isoplot(mumbai_center, locs, 'mumbai_traffic.html')\n",
    "locs2 = get_isodata(mumbai_center, traffic='disabled', departure = '2019-02-13T23:00:00')\n",
    "isoplot(mumbai_center, locs2, 'mumbai_notraffic2.html')\n",
    "\n",
    "new_york_center = (40.754177, -73.984632)\n",
    "locsny = get_isodata(new_york_center, traffic='enabled', departure = '2019-02-13T17:00:00')\n",
    "isoplot(new_york_center, locsny, 'ny_traffic.html')\n",
    "\n",
    "\n",
    "\n",
    "#hereapi.isoplot(home, locs,'red','out.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns area of a geoseries in square kilometers\n",
    "def geoseries_area(geoser):\n",
    "    area_ser = geoser.to_crs({'proj':'cea'})\n",
    "    return (area_ser.area[0] / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads in US cities shapefiles from cbsa\n",
    "\n",
    "from geopandas import GeoSeries\n",
    "us_shp_fp = \"tl_2017_us_cbsa/tl_2017_us_cbsa.shp\"\n",
    "cbsa_data = gpd.read_file(us_shp_fp)\n",
    "\n",
    "#Reads in US_counties shapefiles\n",
    "US_counties_name = 'UScounties/UScounties.shp'\n",
    "US_counties = gpd.read_file(US_counties_name)\n",
    "US_counties.crs = {'init' : 'epsg:4326'} \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads in Oecd Functional urban areas and the function returns the shapefile for a desired\n",
    "#city by fuaname \n",
    "\n",
    "chicago_center = (41.8781136, -87.6297982)\n",
    "us_shp_fp = \"United States/United States.shp\"\n",
    "oecd_data = gpd.read_file(us_shp_fp)\n",
    "\n",
    "\n",
    "def return_cityshp_oecd(city_name):\n",
    "    shp =  oecd_data[oecd_data.fuaname == city_name]\n",
    "    shp = shp.reset_index()\n",
    "    geoshp = shp.geometry\n",
    "    geoshp.crs = {'init' :'epsg:4326'}\n",
    "    return geoshp\n",
    "        \n",
    "\n",
    "chicago_shp = return_cityshp_oecd('Chicago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the marginal percentage areas that each isoline covers a city shapefile until the\n",
    "#isoline completely engulfs the city shapefile. Each iteration increases isoline by 10 minutes. \n",
    "\n",
    "def cumulative_areas(center, oecd_shape):\n",
    "    used_shape = oecd_shape.copy()\n",
    "    oecd_area = geoseries_area(oecd_shape)\n",
    "    overlap = 10000\n",
    "    time = 600\n",
    "    data_list = []\n",
    "    locs_all = []\n",
    "    cumu_area = overlap/oecd_area \n",
    "    while (cumu_area > 0):\n",
    "        isoline = get_isodata(center, range_iso = time, traffic = 'enabled', departure = '2019-02-13T16:00:00')\n",
    "        overlap = geoseries_area(isoline.intersection(used_shape))\n",
    "        cumu_area = overlap/oecd_area\n",
    "        data_list.append((time/60, cumu_area))\n",
    "        used_shape = used_shape.difference(isoline)\n",
    "        time += 600\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots data produced by cumulative_areas function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cumu_data(data):\n",
    "    plt.plot([i[0] for i in data], np.cumsum([i[2] for i in data]), c='blue')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the intersection of the biggest isoline produced by the cumulative_areas function\n",
    "\n",
    "def intersection_union(center, cum_areas, oecd_shape):\n",
    "    time,v = cum_areas[-1]\n",
    "    time = int(time) * 60\n",
    "    isoline = get_isodata(center, time, traffic = 'enabled', departure = '2019-02-13T16:00:00')\n",
    "    intersection = geoseries_area(isoline.intersection(oecd_shape))\n",
    "    union = geoseries_area(isoline.union(oecd_shape))\n",
    "    return intersection/union\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns cumulative_areas data and intersection over union data for a selection of metros\n",
    "#area larger than 15037776415\n",
    "\n",
    "def metros_cumu_areas(cbsa_data): \n",
    "    is_metro = cbsa_data['LSAD'] == 'M1'\n",
    "    metros = cbsa_data[is_metro]\n",
    "    is_big = metros['ALAND'] > 15037776415\n",
    "    big_metros = metros[is_big]\n",
    "    metros = big_metros.reset_index()\n",
    "    CBSAFP = []\n",
    "    names = []\n",
    "    coords = []\n",
    "    shapefiles = []\n",
    "    cumu_areas = []\n",
    "    iou_biggest = []\n",
    "    for i, row in metros.iterrows():\n",
    "        names.append(row['NAME'])\n",
    "        CBSAFP.append(row['CBSAFP'])\n",
    "        coords.append((float(row['INTPTLAT']), float(row['INTPTLON'])))\n",
    "        geoshp = GeoSeries(row['geometry'])\n",
    "        geoshp.crs = {'init' :'epsg:4326'}\n",
    "        shapefiles.append(geoshp)\n",
    "        try:\n",
    "            cumu_area = cumulative_areas(coords[i], shapefiles[i])\n",
    "            cumu_areas.append(cumu_area)\n",
    "            iou_biggest.append(intersection_union(coords[i], cumu_area, shapefiles[i]))\n",
    "        except ValueError:\n",
    "            cumu_area = [(0,0)]\n",
    "            cumu_areas.append(cumu_area)\n",
    "            iou_biggest.append(0.0)\n",
    "    return (cumu_areas, iou_biggest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a data frame of data produced by function metros_cumu_areas and produces csv files\n",
    "\n",
    "def cumu_areas_to_df(cumu_areas, iou_biggest)\n",
    "    IOU_d = {'CBSAFP': CBSAFP, 'Names' : names, 'IOU' : iou_biggest}\n",
    "    IOU_data = pd.DataFrame(data=IOU_d)\n",
    "    CBSAFP_cumu = []\n",
    "    names_cumu = []\n",
    "    cumu_times_opened = []\n",
    "    cumu_percents_opened = []\n",
    "    for i, table in enumerate(cumu_areas):\n",
    "        for time, percent in table:\n",
    "            CBSAFP_cumu.append(CBSAFP[i])\n",
    "            names_cumu.append(names[i])\n",
    "            cumu_times_opened.append(time)\n",
    "            cumu_percents_opened.append(percent)\n",
    "    CA_d = {'CBSAFP' : CBSAFP_cumu, 'Names' : names_cumu, \n",
    "            'Isoline Time Buckets' : cumu_times_opened, \n",
    "            'Percentages' : cumu_percents_opened}\n",
    "    CA_data = pd.DataFrame(data = CA_d)\n",
    "    CA_data.to_csv('CA_data.csv')\n",
    "    IOU_data.to_csv('IOU_data.csv')\n",
    "    return IOU_data, CA_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns marginal population data from a merged data frame\n",
    "\n",
    "pop_code = 'B01003_001E'\n",
    "\n",
    "import censusdata\n",
    "from census import Census\n",
    "\n",
    "def marginal_population(merged_data):\n",
    "    c = Census(census_API_key)\n",
    "    data = []\n",
    "    for a in range(16): #getvalue somehowelse\n",
    "        data.append(0)\n",
    "    state_data = []\n",
    "    for state in merged_data.STATEFP.unique():\n",
    "        state_data.extend(c.acs5.state_county_tract(pop_code, state, Census.ALL, Census.ALL))\n",
    "    for index, d in enumerate(state_data):\n",
    "        q = merged_data[(merged_data.STATEFP == d['state']) & \n",
    "                        (merged_data.COUNTYFP == d['county']) & \n",
    "                        (merged_data.TRACTCE == d['tract'])]\n",
    "        print(q)\n",
    "        if q.empty:\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                data[q.index_right.item()] += d[pop_code]\n",
    "            except KeyError:\n",
    "                data[q.index_right.item()] = d[pop_code]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function returns a data frame consisting of the marginal population and areas of each\n",
    "#isoline increasing in 10 minutes. The function is given co-ordinates of the center of cities\n",
    "#and runs until it reaches 98% percentage of the city. \n",
    "\n",
    "import censusdata\n",
    "from census import Census\n",
    "\n",
    "bg_name = 'BG/tl_2018_{}_bg/tl_2018_{}_bg.shp'\n",
    "pop_code = 'B01003_001E'\n",
    "c = Census(config.census_api_key)\n",
    "\n",
    "def isoline_pops(center, city_shape):\n",
    "    used_shape = city_shape.copy()\n",
    "    city_area = geoseries_area(city_shape)\n",
    "    count = 0\n",
    "    overlap = 10000\n",
    "    time = 600\n",
    "    times = []\n",
    "    marginal_pops = []\n",
    "    cumu_area = overlap/city_area \n",
    "    cumu_areas = []\n",
    "    areas = []\n",
    "    geometries = []\n",
    "    merged = gpd.GeoDataFrame()\n",
    "    states = []\n",
    "    state_data = []\n",
    "    states_read = dict()\n",
    "    st_county_read = dict()\n",
    "    while (sum(cumu_areas) < 0.98 and count<24): \n",
    "        isoline = get_isodata(center, range_iso = time, traffic = 'enabled', departure = '2019-02-13T16:00:00')\n",
    "        if count==0:\n",
    "            isoline_gdf = gpd.GeoDataFrame(geometry = isoline)\n",
    "            isoline_gdf.crs = {'init':'epsg:4326'}\n",
    "        else:\n",
    "            isoline_gdf = gpd.GeoDataFrame(geometry = isoline.difference(prev_isoline))\n",
    "            isoline_gdf.crs = {'init':'epsg:4326'}\n",
    "        states = gpd.sjoin(US_counties, isoline_gdf, op=\"intersects\").STATE_FIPS.unique()\n",
    "        for state in states:\n",
    "            if state in states_read.keys():\n",
    "                pass\n",
    "            else:\n",
    "                bg_new = gpd.read_file(bg_name.format(state,state))\n",
    "                bg_new.crs = ({'init':'epsg:4326'})\n",
    "                states_read[state] = bg_new\n",
    "                merged = pd.concat([merged, bg_new])\n",
    "        marginal_pops.append(0)\n",
    "        current_iso = gpd.sjoin(merged, isoline_gdf, op='intersects')\n",
    "        for index, row in current_iso.iterrows():\n",
    "            state_county = row['STATEFP'] + row['COUNTYFP']\n",
    "            if not (state_county) in st_county_read.keys():\n",
    "                st_county_read[state_county] = dict()\n",
    "                county_bg_data = c.acs5.state_county_blockgroup(pop_code, row['STATEFP'], row['COUNTYFP'], Census.ALL)\n",
    "                for d in county_bg_data:\n",
    "                    st_county_read[state_county][state_county + d['tract'] + d['block group']] = d[pop_code]\n",
    "            marginal_pops[count] += st_county_read[state_county][row['GEOID']]\n",
    "            isoline = isoline.union(row['geometry'])\n",
    "        overlap = geoseries_area(isoline.intersection(used_shape))\n",
    "        geometries.append(isoline[0])\n",
    "        times.append(time/60)\n",
    "        areas.append(geoseries_area(isoline))\n",
    "        cumu_area = overlap/city_area\n",
    "        cumu_areas.append(cumu_area)\n",
    "        used_shape = used_shape.difference(isoline)\n",
    "        if count == 0:\n",
    "            prev_isoline = gpd.GeoDataFrame(geometry = isoline)\n",
    "            prev_isoline.crs = {'init' : 'epsg:4326'}\n",
    "        else :\n",
    "            prev_isoline = gpd.GeoDataFrame(geometry = prev_isoline.union(isoline))\n",
    "            prev_isoline.crs = {'init' : 'epsg:4326'}\n",
    "        time += 600\n",
    "        count += 1\n",
    "        print(count, cumu_area)\n",
    "    optima = []\n",
    "    for index, num in enumerate(marginal_pops):\n",
    "        try:\n",
    "            if num > marginal_pops[index+1] and num > marginal_pops[index-1]:\n",
    "                optima.append(1)\n",
    "            else:\n",
    "                optima.append(0)\n",
    "        except IndexError:\n",
    "            optima.append(0)\n",
    "    return_dict = {'Times' : times, \n",
    "                   'Cumulative Areas' : cumu_areas, \n",
    "                   'Areas' : areas,\n",
    "                   'Marginal Population' : marginal_pops,\n",
    "                  'Optima' : optima}\n",
    "    return_frame = pd.DataFrame(data = return_dict)\n",
    "    return return_frame\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Takes in list of cities with index, city name, state abbreviation as well as CBSA shapefiles\n",
    "#and returns a dataframe of each cities with their marginal populations, cumulative areas, \n",
    "#local optima \n",
    "\n",
    "import re\n",
    "google_api = \"https://maps.googleapis.com/maps/api/geocode/json?address={}+{}&key=\" + config.google_api_key\n",
    "with open('top_cities.txt', 'r') as f:\n",
    "        cities = f.readlines()\n",
    "\n",
    "def top_30_pop_data(cities, cbsa_data):\n",
    "    car_data_30 = pd.DataFrame()\n",
    "    for row in cities:\n",
    "        metro = row.split(',')\n",
    "        city = metro[1]\n",
    "        state = metro[2]\n",
    "        print(state)\n",
    "        is_metro = cbsa_data['LSAD'] == 'M1'\n",
    "        metro_data = cbsa_data[is_metro]\n",
    "        metro_data = metro_data[metro_data['NAME'].str.contains(city)]\n",
    "        if len(metro_data) != 1:\n",
    "            shp = metro_data[metro_data['NAME'].str.contains(state)]\n",
    "        else:\n",
    "            shp = metro_data[metro_data['NAME'].str.contains(city)]\n",
    "        shp = shp.reset_index()\n",
    "        geoshp = GeoSeries(shp['geometry'])\n",
    "        geoshp.crs = {'init' : 'epsg:4326'}\n",
    "        city = re.sub(r'\\s+', '+', city)\n",
    "        city = city.replace('.', '')\n",
    "        url = google_api.format(city, state)\n",
    "        js = requests.get(url).json()['results'][0]['geometry']\n",
    "        lat = js['location']['lat']\n",
    "        long = js['location']['lng']\n",
    "        coords = (float(lat), float(long))\n",
    "        print(city, state)\n",
    "        print(coords)\n",
    "        try:\n",
    "            pop_data = isoline_pops(coords, geoshp)\n",
    "            cbs_list = []\n",
    "            name_list = []\n",
    "            for a in range(0, len(pop_data)):\n",
    "                cbs_list.append(shp['CBSAFP'][0])\n",
    "                name_list.append(shp['NAME'][0])\n",
    "            pop_data.insert(loc = 0, column = 'CBSAFP', value=cbs_list)\n",
    "            pop_data.insert(loc = 1, column = 'NAME', value=name_list)\n",
    "            car_data_30 = pd.concat([car_data_30, pop_data], sort=False)\n",
    "            car_data_30.to_csv('car_data_30.csv')\n",
    "        except (KeyboardInterrupt, SystemExit) as r:\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print('error', e)\n",
    "            pass\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
